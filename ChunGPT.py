import streamlit as st
from openai import OpenAI
import datetime
from respositories.client_respository import (
    Repository_client,
)  # Import your repository class

# Set up your SQLite database path (adjust if necessary)
db_path = "client_db_1.sqlite3"
repo_client = Repository_client(db_path)

st.set_page_config(page_title="ChunGPT", initial_sidebar_state="auto")

# url_ngrok = "https://da22-171-243-49-10.ngrok-free.app"
url_local = "http://localhost:11434"

# Get today's date
today = datetime.datetime.now().strftime("%Y-%m-%d")

# Custom AI instructions
custom_ai = f"""
        - H√¥m nay: {today}.
        - B·∫°n l√† ChunGPT.
        - B·∫°n l√† m·ªôt assistant t·∫≠n t√¢m.
        - B·∫°n nhi·ªát huy·∫øt v√† lu√¥n c·ªë g·∫Øng th·ª±c hi·ªán theo y√™u c·∫ßu c·ªßa t√¥i h·∫øt m√¨nh v√† ƒë·∫ßy ƒë·ªß.
        - B·∫°n lu√¥n c√≥ th·ªÉ k√®m link ·ªü cu·ªëi tin nh·∫Øn ƒë·ªÉ th√™m th√¥ng tin cho ng∆∞·ªùi d√πng.
        - B·∫°n c√≥ th·ªÉ ƒë∆∞a emoji v√†o t√πy tr∆∞·ªùng h·ª£p.
        - Tr·ª´ ti·∫øng Anh v√† Ti·∫øng Vi·ªát, b·∫°n kh√¥ng ƒë∆∞a ng√¥n ng·ªØ kh√°c v√†o.
        - No Yapping, Limit Prose, No Fluff
    """

# Sidebar: API key input
with st.sidebar:
    ollama_api_key = "ollama"
    "[My source](https://github.com/Chunn241529/ChunGPT/blob/main/ui/ChunGPT.py) üóÉÔ∏è"
    "[Buy me a coffee](https://github.com/Chunn241529/ChunGPT/blob/main/ui/assets/img/buymecoffee.png?raw=true) ‚ù§Ô∏è"
    button_clicked = st.sidebar.button("X√≥a tin nh·∫Øn")
    if button_clicked:
        repo_client.delete_brain_history_chat_all()


st.title("üí¨ ChunGPT")
st.caption("üöÄ ChungGPT ƒë∆∞·ª£c cung c·∫•p b·ªüi OllamaAI")

history = repo_client.get_brain_history_chat()

# Initialize message state with custom AI instructions
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": custom_ai},  # Add system instructions
        {"role": "assistant", "content": "Ch√†o, t√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"},
    ]
    # If there is any existing history, add it to the session state
    if history:
        for _, role, content, _ in history:
            st.session_state["messages"].append({"role": role, "content": content})

# Display previous messages (but exclude system message from the chat)
for msg in st.session_state.messages:
    if msg["role"] != "system":
        st.chat_message(msg["role"]).write(msg["content"])


def generate_llama2_response(prompt):
    """Function to generate response from the AI server."""
    client = OpenAI(
        base_url=f"{url_local}/v1",
        api_key=ollama_api_key,
    )

    # S·ª≠ d·ª•ng stream ƒë·ªÉ nh·∫≠n d·ªØ li·ªáu t·ª´ng ph·∫ßn, gi√∫p ph·∫£n h·ªìi nhanh h∆°n
    response = client.chat.completions.create(
        model="qwen2.5-coder:7b",
        messages=st.session_state["messages"],
        stream=True,
    )

    return response


# Input from user
if prompt := st.chat_input(placeholder="Nh·∫≠p tin nh·∫Øn..."):
    if not ollama_api_key:
        st.info("Please add your Ollama API key to continue.")
        st.stop()

    # Append user input to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # Insert the user message into the database
    repo_client.insert_brain_history_chat(role="user", content=prompt)

    # Generate a new response if last message is not from assistant
    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            # Create a placeholder for the spinner and response
            spinner_placeholder = st.empty()
            response_placeholder = st.empty()

            with spinner_placeholder:
                with st.spinner(""):  # Hi·ªÉn th·ªã spinner trong khi ƒëang x·ª≠ l√Ω
                    # G·ªçi h√†m l·∫•y ph·∫£n h·ªìi t·ª´ AI v·ªõi stream
                    response = generate_llama2_response(prompt)
                    full_response = ""

                    # Hi·ªÉn th·ªã ph·∫£n h·ªìi t·ª´ng ph·∫ßn
                    for chunk in response:
                        content = (
                            chunk.choices[0].delta.content
                            if hasattr(chunk.choices[0].delta, "content")
                            else ""
                        )
                        full_response += content
                        response_placeholder.markdown(
                            full_response
                        )  # C·∫≠p nh·∫≠t m·ªói ph·∫ßn c·ªßa ph·∫£n h·ªìi

                    # Sau khi c√≥ ƒë·ªß ph·∫£n h·ªìi, x√≥a spinner
                    spinner_placeholder.empty()

                # Th√™m ph·∫£n h·ªìi v√†o l·ªãch s·ª≠ tin nh·∫Øn
                st.session_state.messages.append(
                    {"role": "assistant", "content": full_response}
                )

                # Insert the assistant's response into the database
                repo_client.insert_brain_history_chat(
                    role="assistant", content=full_response
                )
