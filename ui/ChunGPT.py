import streamlit as st
from openai import OpenAI
import datetime

# Get today's date
today = datetime.datetime.now().strftime("%Y-%m-%d")

# Custom AI instructions
custom_ai = f"""
        - H√¥m nay: {today}.
        - B·∫°n l√† ChunGPT.
        - B·∫°n l√† m·ªôt assistant t·∫≠n t√¢m.
        - B·∫°n nhi·ªát huy·∫øt v√† lu√¥n c·ªë g·∫Øng th·ª±c hi·ªán theo y√™u c·∫ßu c·ªßa t√¥i h·∫øt m√¨nh v√† ƒë·∫ßy ƒë·ªß.
        - B·∫°n lu√¥n c·ªë g·∫Øng k√®m th√™m link ·ªü cu·ªëi tin nh·∫Øn ƒë·ªÉ th√™m th√¥ng tin cho ng∆∞·ªùi d√πng.
    """

# Sidebar: API key input
with st.sidebar:
    ollama_api_key = "ollama"
    "[View the source code](https://github.com/Chunn241529/ChunGPT/blob/main/ui/ChunGPT.py)"

st.title("üí¨ ChunGPT")
st.caption("üöÄ ChunGPT powered by Ollama")

# Initialize message state with custom AI instructions
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": custom_ai},  # Add system instructions
        {"role": "assistant", "content": "Ch√†o, t√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"},
    ]

# Display previous messages (but exclude system message from the chat)
for msg in st.session_state.messages:
    if msg["role"] != "system":
        st.chat_message(msg["role"]).write(msg["content"])


def generate_llama2_response(prompt):
    """Function to generate response from the AI server."""
    client = OpenAI(
        base_url="https://8668-171-243-49-10.ngrok-free.app/v1",
        api_key=ollama_api_key,
    )
    response = client.chat.completions.create(
        model="qwen2.5:14b", messages=st.session_state["messages"]
    )
    return response.choices[0].message.content


# Input from user
if prompt := st.chat_input(placeholder=" Nh·∫≠p tin nh·∫Øn..."):
    if not ollama_api_key:
        st.info("Please add your Ollama API key to continue.")
        st.stop()

    # Append user input to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # Generate a new response if last message is not from assistant
    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            with st.spinner("ü§î"):
                response = generate_llama2_response(prompt)
                placeholder = st.empty()
                full_response = ""
                for item in response:
                    full_response += item
                    placeholder.markdown(full_response)
                placeholder.markdown(full_response)
        message = {"role": "assistant", "content": full_response}
        st.session_state.messages.append(message)
