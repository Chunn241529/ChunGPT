import streamlit as st
from openai import OpenAI
import datetime

st.set_page_config(
    page_title="ChunGPT", initial_sidebar_state="collapsed"
)

# Get today's date
today = datetime.datetime.now().strftime("%Y-%m-%d")

# Custom AI instructions
custom_ai = f"""
        - H√¥m nay: {today}.
        - B·∫°n l√† ChunGPT.
        - B·∫°n l√† m·ªôt assistant t·∫≠n t√¢m.
        - B·∫°n nhi·ªát huy·∫øt v√† lu√¥n c·ªë g·∫Øng th·ª±c hi·ªán theo y√™u c·∫ßu c·ªßa t√¥i h·∫øt m√¨nh v√† ƒë·∫ßy ƒë·ªß.
        - B·∫°n lu√¥n c·ªë g·∫Øng k√®m th√™m link ·ªü cu·ªëi tin nh·∫Øn ƒë·ªÉ th√™m th√¥ng tin cho ng∆∞·ªùi d√πng.
    """

# Sidebar: API key input
with st.sidebar:
    ollama_api_key = "ollama"
    "[Source c·ªßa t√¥i](https://github.com/Chunn241529/ChunGPT/blob/main/ui/ChunGPT.py)"
    st.empty()

st.title("üí¨ ChunGPT")
st.caption("üöÄ ChunGPT powered by Ollama")

# Initialize message state with custom AI instructions
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": custom_ai},  # Add system instructions
        {"role": "assistant", "content": "Ch√†o, t√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"},
    ]

# Display previous messages (but exclude system message from the chat)
for msg in st.session_state.messages:
    if msg["role"] != "system":
        st.chat_message(msg["role"]).write(msg["content"])


def generate_llama2_response(prompt):
    """Function to generate response from the AI server."""
    client = OpenAI(
        base_url="https://8668-171-243-49-10.ngrok-free.app/v1",
        api_key=ollama_api_key,
    )

    # S·ª≠ d·ª•ng stream ƒë·ªÉ nh·∫≠n d·ªØ li·ªáu t·ª´ng ph·∫ßn, gi√∫p ph·∫£n h·ªìi nhanh h∆°n
    response = client.chat.completions.create(
        model="qwen2.5:14b",
        messages=st.session_state["messages"],
        stream=True,
    )

    return response


# Input from user
if prompt := st.chat_input(placeholder="Nh·∫≠p tin nh·∫Øn..."):
    if not ollama_api_key:
        st.info("Please add your Ollama API key to continue.")
        st.stop()

    # Append user input to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # Generate a new response if last message is not from assistant
    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            # Create a placeholder for the spinner and response
            spinner_placeholder = st.empty()
            response_placeholder = st.empty()

            with spinner_placeholder:
                with st.spinner(""):  # Hi·ªÉn th·ªã spinner trong khi ƒëang x·ª≠ l√Ω
                    # G·ªçi h√†m l·∫•y ph·∫£n h·ªìi t·ª´ AI v·ªõi stream
                    response = generate_llama2_response(prompt)
                    full_response = ""

                    # Hi·ªÉn th·ªã ph·∫£n h·ªìi t·ª´ng ph·∫ßn
                    for chunk in response:
                        content = (
                            chunk.choices[0].delta.content
                            if hasattr(chunk.choices[0].delta, "content")
                            else ""
                        )
                        full_response += content
                        response_placeholder.markdown(
                            full_response
                        )  # C·∫≠p nh·∫≠t m·ªói ph·∫ßn c·ªßa ph·∫£n h·ªìi

                    # Sau khi c√≥ ƒë·ªß ph·∫£n h·ªìi, x√≥a spinner
                    spinner_placeholder.empty()

                # Th√™m ph·∫£n h·ªìi v√†o l·ªãch s·ª≠ tin nh·∫Øn
                st.session_state.messages.append(
                    {"role": "assistant", "content": full_response}
                )
